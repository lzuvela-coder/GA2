---
title: "Your Title"
subtitle: "STAT 253: Statistical Machine Learning"
date: today
author: "Your Names"
format:
  html:
    toc: true
    toc-depth: 3
    embed-resources: true
    code-tools: true
---



<!-- Your report should follow the format specified in the Group Assignment 2 Instructions. Please review that document carefully! -->





```{r}
#| include: false
# Load packages 
library(tidyverse)
library(tidymodels)
library(rpart)
library(rpart.plot)
library(vip)

# Resolves package conflicts by preferring tidymodels functions
tidymodels_prefer()

# if your group needs any other packages, add them here
# Load packages
library(kknn)        # for KNN
library(rpart.plot)  # for plotting trees
library(class)       # for my plotting functions
library(vip)
```


# Research Goals

The goal of this report is to build a predictive classification model that can determine a kangarooâ€™s species from skull measurements. Correctly identifying species from skeletal features is useful in ecological monitoring, museum curation, and Paleontology field research where complete specimens are rare. In addition to developing and evaluating our predictive algorithm, we aim to highlight which skull characteristics most strongly distinguish species, supported by visualizations and model-based evidence.

# Data

```{r}
#| message: false
#| warning: false
#| echo: false

kangaroo_data <-read_csv("kangaroo.csv")

head(kangaroo_data)

clean_kangaroo<-kangaroo_data %>% 
  select(-palate.width, -occipital.depth, -mandible.length)

sum(is.na(kangaroo_data))

sum(is.na(clean_kangaroo))

clean_kangaroo<-na.omit(clean_kangaroo)
colnames(clean_kangaroo)
```

```{r}
#| message: false
#| warning: false
#| echo: false

# visualization

ggplot(aes(x=species, color=species), data= clean_kangaroo)+
  geom_density()

ggplot(aes(y=.rostral.width, x=species, color=sex ), data=clean_kangaroo, )+
  geom_boxplot()+
  facet_wrap(~sex)

ggplot(clean_kangaroo, aes(y = .rostral.width, x = nasal.width, color = species)) + 
  geom_point() + 
  theme_minimal()

```

```{r}
tree_spec <- decision_tree() %>%
  set_mode("classification") %>%
  set_engine("rpart") %>%
  set_args(cost_complexity = tune(), min_n = 2, tree_depth = 30)

tree_recipe <- recipe(species ~ ., data = kangaroo)

tree_wf <- workflow() %>%
  add_recipe(tree_recipe) %>%
  add_model(tree_spec)


set.seed(253)
tree_models <- tree_wf %>%
  tune_grid(
    grid = grid_regular(cost_complexity(range = c(-5, 0.1)), levels = 20),
    resamples = rs,
    metrics = metric_set(accuracy))

best_cost <- select_best(tree_models, metric = "accuracy")
final_tree <- tree_wf %>% finalize_workflow(best_cost) %>% fit(kangaroo)

final_tree %>% extract_fit_engine() %>% rpart.plot()
```

tree_models %>%
  collect_metrics() %>%
  dplyr::filter(.metric == "accuracy") %>%
  dplyr::arrange(desc(mean)) %>% 
  dplyr::slice(1)

```{r}
rf_spec <- rand_forest() %>%
  set_mode("classification") %>%
  set_engine("ranger") %>%
  set_args(
    mtry = NULL,
    trees = 500,
    min_n = 2,
    probability = FALSE,
    importance = "impurity")

age_forest <- rf_spec %>% fit(species ~ ., data = kangaroo)

imp_vec <- age_forest %>% extract_fit_engine() %>%
  pluck("variable.importance") %>% sort(decreasing = TRUE)
imp_vec

age_forest %>% vip(geom = "point", num_features = 15)
```

# Model Building


```{r}
knn_spec <- nearest_neighbor() %>%
  set_mode("classification") %>% 
  set_engine(engine = "kknn") %>% 
  set_args(neighbors = tune())

variable_recipe <- recipe(species ~ basilar.length, nasal.length, nasal.width, lacrimal.width, orbital.width, mandible.width, ramus.height, data = clean_kangaroo) %>% 
  step_nzv(all_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors())

knn_workflow <- workflow() %>% 
  add_recipe(variable_recipe) %>% 
  add_model(knn_spec)

set.seed(253)
knn_models <- knn_workflow %>% 
  tune_grid(
    grid = grid_regular(neighbors(range = c(1, 74)), levels = 50),
    resamples = vfold_cv(clean_kangaroo, v = 10),
    metrics = metric_set(accuracy, sensitivity, specificity)
  )

```

```{r}
knn_models %>% 
  autoplot()
```

```{r}
best_k <- knn_models %>% 
  select_best()
best_k

knn_models %>% 
  collect_metrics() %>% 
  filter(neighbors == best_K$neighbors)
```
```{r}
final_knn_model <- knn_workflow %>% 
  finalize_workflow(parameters = best_k) %>% 
  fit(data = clean_kangaroo)
```



# Implementation

We used tidymodels to implement this model building process. See code below for full details.

<details>
<summary>View Code</summary>

```{r}
#| message: false
#| warning: false

# Include all model building code in here.
# Make sure to include comments explaining what your code does.

# LASSO
lasso_spec <- linear_reg() %>% 
  set_mode("regression") %>% 
  set_engine("glmnet") %>% 
  set_args(mixture = 1, penalty = tune())

kangaroo_recipe <- recipe(group_species ~ ., data = lasso_kangaroo) %>% 
  step_nzv(all_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors())

lasso_workflow <- workflow() %>% 
  add_recipe(kangaroo_recipe) %>% 
  add_model(lasso_spec)

set.seed(253)
lasso_models <- lasso_workflow %>% 
  tune_grid(
    grid = grid_regular(penalty(range = c(-5, 1)), levels = 75),
    resamples = vfold_cv(lasso_kangaroo, v = 15),
    metrics = metric_set(mae)
  )

parsimonious_penalty <- lasso_models %>% 
  select_by_one_std_err(metric = "mae", desc(penalty))

final_lasso_model <- lasso_workflow %>% 
  finalize_workflow(parameters = parsimonious_penalty) %>% 
  fit(data = lasso_kangaroo)

final_lasso_model %>% 
  tidy()

## vars = basilar.length, nasal.length, nasal.width, lacrymal.width, orbital.width, mandible.width, ramus.height

# logistic regression
combo_kangaroo <- clean_kangaroo %>% 
  mutate(group_species = case_when(
    species == "giganteus" ~ "giganteus", 
    species %in% c("fuliginosus", "melanops") ~ "fuliginosus")) %>%
  select(-species)

logistic_spec <- logistic_reg() %>%
  set_mode("classification") %>% 
  set_engine("glm")

kangaroo_recipe <- recipe(group_species ~ basilar.length + nasal.length + nasal.width + lacrymal.width + orbital.width + mandible.width + ramus.height, data = combo_kangaroo)

logistic_workflow <- workflow() %>% 
  add_recipe(kangaroo_recipe) %>%
  add_model(logistic_spec) 

log_kangaroo <- logistic_workflow %>% 
  fit(data = combo_kangaroo)

set.seed(253)
log_kangaroo_cv <- log_kangaroo %>% 
  fit_resamples(
    group_species ~ basilar.length + nasal.length + nasal.width + lacrymal.width + orbital.width + mandible.width + ramus.height,
    resamples = vfold_cv(combo_kangaroo, v = 10), 
    control = control_resamples(save_pred = TRUE, event_level = 'second'),
    metrics = metric_set(accuracy, sensitivity, specificity)
  )

log_kangaroo_cv %>% 
  collect_metrics()


#KNN

knn_spec <- nearest_neighbor() %>%
  set_mode("classification") %>%
  set_engine(engine = "kknn") %>%
  set_args(neighbors = tune())

variable_recipe <- recipe(species ~ basilar.length, nasal.length, nasal.width, lacrimal.width, orbital.width, mandible.width, ramus.height, data = clean_kangaroo) %>%
  step_nzv(all_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors())

knn_workflow <- workflow() %>%
  add_recipe(variable_recipe) %>%
  add_model(knn_spec)

set.seed(253)
knn_models <- knn_workflow %>%
  tune_grid(
    grid = grid_regular(neighbors(range = c(1, 74)), levels = 50),
    resamples = vfold_cv(clean_kangaroo, v = 10),
    metrics = metric_set(accuracy, sensitivity, specificity)
  )

knn_models %>%
  autoplot()

best_k <- knn_models %>%
  select_best()
best_k

knn_models %>%
  collect_metrics() %>%
  filter(neighbors == best_K$neighbors)

final_knn_model <- knn_workflow %>%
  finalize_workflow(parameters = best_k) %>%
  fit(data = clean_kangaroo)

```

</details>



# Model Evaluation

```{r}
#| message: false
#| warning: false
#| echo: false

# visualization

```



# Contributions



# Appendix

```{r}
#| eval: false
# put code for any other models or visualizations that you considered here
# use comments to explain what your code is doing
```

## logistic- William
```{r}
kangaroo_log_df<- clean_kangaroo

kangaroo_log_df$species <- ifelse(kangaroo_log_df$species %in% c("melanops", "fuliginosus"),
                                 "fuliginosus", kangaroo_log_df$species)

kangaroo_log_df <- kangaroo_log_df %>%
  mutate(species = relevel(as.factor(species), ref = "giganteus"))


kangaroo_recipe <- recipe(species ~ basilar.length + nasal.width + zygomatic.width + mandible.depth,
                          data = kangaroo_log_df) %>%
  step_normalize(all_predictors())


log_model <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

kangaroo_wf <- workflow() %>%
  add_model(log_model) %>%
  add_recipe(kangaroo_recipe)

kangaroo_fit <- fit(kangaroo_wf, data = kangaroo_log_df)

# Get a summary table
kangaroo_fit %>%
  tidy()

kangaroo_fit %>%
  tidy() %>%
  mutate(
    OR = exp(estimate),
    OR.conf.low = exp(estimate - 1.96*std.error),
    OR.conf.high = exp(estimate + 1.96*std.error)
  )



```


```{r}
kangaroo_fit %>%
  augment(new_data = kangaroo_log_df)
```
```{r}
kangaroo_predictions <- kangaroo_fit %>%
  augment(new_data = kangaroo_log_df)

accuracy <- kangaroo_predictions %>%
  accuracy(truth = species, estimate = .pred_class)

accuracy

conf_mat <- kangaroo_predictions %>%
  conf_mat(truth = species, estimate = .pred_class)

conf_mat

classification_metrics <- kangaroo_predictions %>%
  metrics(truth = species, estimate = .pred_class)

classification_metrics
```

```{r}
#| message: false
#| warning: false
#| echo: false

# Load yardstick for metrics (if not already loaded)
library(yardstick)

# Set seed for reproducibility
set.seed(320)

# Create cross-validation folds (10-fold CV)
kangaroo_cv <- vfold_cv(kangaroo_log_df, v = 10)

# Fit the model using cross-validation
cv_results <- kangaroo_wf %>%
  fit_resamples(
    resamples = kangaroo_cv,
    control = control_resamples(save_pred = TRUE)
  )

# View cross-validation metrics (default: accuracy and roc_auc)
cv_results %>%
  collect_metrics()

# Get detailed metrics
cv_metrics_detailed <- cv_results %>%
  collect_metrics() %>%
  select(.metric, mean, std_err, n)

cv_metrics_detailed

# Visualize accuracy across folds
cv_results %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "accuracy") %>%
  ggplot(aes(x = id, y = .estimate)) +
  geom_point(size = 3, color = "blue") +
  geom_hline(yintercept = mean(collect_metrics(cv_results, summarize = FALSE) %>%
                                  filter(.metric == "accuracy") %>%
                                  pull(.estimate)),
             linetype = "dashed", color = "red") +
  labs(title = "Accuracy Across 10-Fold Cross-Validation",
       x = "Fold",
       y = "Accuracy") +
  theme_minimal() +
  coord_flip()

# Get confusion matrix from CV predictions
cv_results %>%
  collect_predictions() %>%
  conf_mat(truth = species, estimate = .pred_class)
```
