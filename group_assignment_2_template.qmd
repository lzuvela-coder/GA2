---
title: "Your Title"
subtitle: "STAT 253: Statistical Machine Learning"
date: today
author: "Your Names"
format:
  html:
    toc: true
    toc-depth: 3
    embed-resources: true
    code-tools: true
---



<!-- Your report should follow the format specified in the Group Assignment 2 Instructions. Please review that document carefully! -->





```{r}
#| include: false
# Load packages 
library(tidyverse)
library(tidymodels)
library(rpart)
library(rpart.plot)
library(vip)

# Resolves package conflicts by preferring tidymodels functions
tidymodels_prefer()

# if your group needs any other packages, add them here
# Load packages
library(kknn)        # for KNN
library(rpart.plot)  # for plotting trees
library(class)       # for my plotting functions
library(vip)
```


# Research Goals

The goal of this report is to build a predictive classification model that can determine a kangarooâ€™s species from skull measurements. Correctly identifying species from skeletal features is useful in ecological monitoring, museum curation, and Paleontology field research where complete specimens are rare. In addition to developing and evaluating our predictive algorithm, we aim to highlight which skull characteristics most strongly distinguish species, supported by visualizations and model-based evidence.

# Data

```{r}
#| message: false
#| warning: false
#| echo: false

kangaroo_data <-read_csv("kangaroo.csv")

head(kangaroo_data)

clean_kangaroo<-kangaroo_data %>% 
  select(-palate.width, -occipital.depth, -mandible.length)

sum(is.na(kangaroo_data))

sum(is.na(clean_kangaroo))

clean_kangaroo<-na.omit(clean_kangaroo)
colnames(clean_kangaroo)
```

```{r}
#| message: false
#| warning: false
#| echo: false

# visualization

ggplot(aes(x=species, color=species), data= clean_kangaroo)+
  geom_density()

ggplot(aes(y=.rostral.width, x=species, color=sex ), data=clean_kangaroo, )+
  geom_boxplot()+
  facet_wrap(~sex)

ggplot(clean_kangaroo, aes(y = .rostral.width, x = nasal.width, color = species)) + 
  geom_point() + 
  theme_minimal()


```

tree_spec <- decision_tree() %>%
  set_mode("classification") %>%
  set_engine("rpart") %>%
  set_args(cost_complexity = tune(), min_n = 2, tree_depth = 30)

tree_recipe <- recipe(species ~ ., data = kangaroo)

tree_wf <- workflow() %>%
  add_recipe(tree_recipe) %>%
  add_model(tree_spec)


set.seed(253)
tree_models <- tree_wf %>%
  tune_grid(
    grid = grid_regular(cost_complexity(range = c(-5, 0.1)), levels = 20),
    resamples = rs,
    metrics = metric_set(accuracy))

best_cost <- select_best(tree_models, metric = "accuracy")
final_tree <- tree_wf %>% finalize_workflow(best_cost) %>% fit(kangaroo)

final_tree %>% extract_fit_engine() %>% rpart.plot()

# Model Building


```{r}
knn_spec <- nearest_neighbor() %>%
  set_mode("classification") %>% 
  set_engine(engine = "kknn") %>% 
  set_args(neighbors = tune())

variable_recipe <- recipe(species ~ basilar.length, nasal.length, nasal.width, lacrimal.width, orbital.width, mandible.width, ramus.height, data = clean_kangaroo) %>% 
  step_nzv(all_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors())

knn_workflow <- workflow() %>% 
  add_recipe(variable_recipe) %>% 
  add_model(knn_spec)

set.seed(253)
knn_models <- knn_workflow %>% 
  tune_grid(
    grid = grid_regular(neighbors(range = c(1, 74)), levels = 50),
    resamples = vfold_cv(clean_kangaroo, v = 10),
    metrics = metric_set(accuracy, sensitivity, specificity)
  )

```

```{r}
knn_models %>% 
  autoplot()
```

```{r}
best_k <- knn_models %>% 
  select_best()
best_k
```
```{r}
final_knn_model <- knn_workflow %>% 
  finalize_workflow(parameters = best_k) %>% 
  fit(data = clean_kangaroo)
```

Divide 80/20 for training and testing...
```{r}
final_knn_model %>% 
  predict(new_data = ___)     
```



# Implementation

We used tidymodels to implement this model building process. See code below for full details.

<details>
<summary>View Code</summary>

```{r}
#| message: false
#| warning: false

# Include all model building code in here.
# Make sure to include comments explaining what your code does.

# LASSO
combo_kangaroo <- clean_kangaroo %>% 
  mutate(group_species = case_when(
    species == "giganteus" ~ 0, 
    species %in% c("fuliginosus", "melanops") ~ 1)) %>%
  select(-species)

lasso_spec <- linear_reg() %>% 
  set_mode("regression") %>% 
  set_engine("glmnet") %>% 
  set_args(mixture = 1, penalty = tune())

kangaroo_recipe <- recipe(group_species ~ ., data = combo_kangaroo) %>% 
  step_nzv(all_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors())

lasso_workflow <- workflow() %>% 
  add_recipe(kangaroo_recipe) %>% 
  add_model(lasso_spec)

set.seed(253)
lasso_models <- lasso_workflow %>% 
  tune_grid(
    grid = grid_regular(penalty(range = c(-5, 1)), levels = 75),
    resamples = vfold_cv(combo_kangaroo, v = 15),
    metrics = metric_set(mae)
  )

parsimonious_penalty <- lasso_models %>% 
  select_by_one_std_err(metric = "mae", desc(penalty))

final_lasso_model <- lasso_workflow %>% 
  finalize_workflow(parameters = parsimonious_penalty) %>% 
  fit(data = combo_kangaroo)

final_lasso_model %>% 
  tidy()

## vars = basilar.length, nasal.length, nasal.width, lacrymal.width, orbital.width, mandible.width, ramus.height
```

</details>



# Model Evaluation

```{r}
#| message: false
#| warning: false
#| echo: false

# visualization

```



# Contributions



# Appendix

```{r}
#| eval: false
# put code for any other models or visualizations that you considered here
# use comments to explain what your code is doing
```

