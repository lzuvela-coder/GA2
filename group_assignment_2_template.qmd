---
title: "Your Title"
subtitle: "STAT 253: Statistical Machine Learning"
date: today
author: "Your Names"
format:
  html:
    toc: true
    toc-depth: 3
    embed-resources: true
    code-tools: true
---

<!-- Your report should follow the format specified in the Group Assignment 2 Instructions. Please review that document carefully! -->

```{r}
#| include: false
# Load packages 
library(tidyverse)
library(tidymodels)
library(rpart)
library(rpart.plot)
library(vip)

# Resolves package conflicts by preferring tidymodels functions
tidymodels_prefer()

# if your group needs any other packages, add them here
# Load packages
library(kknn)        # for KNN
library(rpart.plot)  # for plotting trees
library(class)       # for my plotting functions
library(vip)
library(yardstick)

```

# Research Goals

The goal of this report is to build a predictive classification model that can determine a kangarooâ€™s species from skull measurements. Correctly identifying species from skeletal features is useful in ecological monitoring, museum curation, and paleontology field research where complete specimens are rare. In addition to developing and evaluating our predictive algorithm, we aim to highlight which skull characteristics most strongly distinguish species, supported by visualizations and model-based evidence.

# Data

The focus outcome variable in this study is 'species' which has three groups: fuliginosus, giganteus, and melanops. From the raw data, we counted with 148 observations and 20 predictor variables including skull features such as nasal length, mandible length and sex among others.

Our training dataset is made up of skull measurements from 148 individual kangaroos collected for research. The who represents three species of kangaroos: fuliginosus (n=50), giganteus (n=50), and melanops (n=48). The what consists of 20 cranial measurements captured in millimeters, including features such as basilar length, nasal dimensions, palate measurements, zygomatic width, and mandible characteristics, along with the sex of each specimen. The why centers on species identification being able to accurately classify kangaroo species from skeletal remains is crucial for paleontological research and ecological monitoring where complete specimens may be unavailable. The how involves precise cranial measurements taken from skulls using standardized morphometric techniques. It is important to metion that fuliginosus and melanops are actually the same biological species since both represent the Western Grey Kangaroo (Macropus fuliginosus) with "melanops" historically used to describe specimens from a specific geographic region before being taxonomically synonymized with fuliginosus. This informed our modeling strategy.

```{r}
#| message: false
#| warning: false
#| echo: false
kangaroo <-read_csv("kangaroo.csv")

 kangaroo%>% 
  count(species) %>%
  knitr::kable(caption = "Species Distribution")

missing_summary <- kangaroo %>% 
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Missing") %>%
  filter(Missing > 0) %>%
  arrange(desc(Missing))

if(nrow(missing_summary) > 0) {
  missing_summary %>%
    knitr::kable(caption = "Missing Values Summary")
}

key_features <- c("basilar.length", "occipitonasal.length", "palate.length",
                  "zygomatic.width", "mandible.length", "nasal.length")

kangaroo %>%
  select(species, all_of(key_features)) %>%
  pivot_longer(cols = -species, names_to = "measurement", values_to = "value") %>%
  ggplot(aes(x = species, y = value, fill = species)) +
  geom_boxplot() +
  facet_wrap(~ measurement, scales = "free_y", ncol = 3) +
  labs(title = "Key Skull Measurements by Species",
       x = "Species", 
       y = "Measurement (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom")

```



The boxplot visualization reveals that giganteus (Eastern Grey Kangaroo) shows distinctly larger nasal measurements compared to the other two groups, while fuliginosus and melanops display remarkably similar median distributions across most skull features, consistent with them being the same species. This visual evidence supported our decision to group these two categories together for classification purposes.





# Model Building

Our model building process began with the critical biological insight that fuliginosus and melanops represent the same species, the Western Grey Kangaroo (Macropus fuliginosus), with melanops being a geographic variant. Instead of training our model to distinguish between the three categories, we reframed the problem to reflect the actual biological taxonomy by grouping fuliginosus and melanops together versus giganteus (Eastern Grey Kangaroo). This decision transformed our three class problem into a binary classification task, which aligns with biological reality and improves model performance and interpretability. The boxplot visualization from the section earlier supported this approach, showing that fuliginosus and melanops have mostly similar median skull measurement distributions across all features, while giganteus displays distinct morphological differences, particularly in nasal dimensions.

To identify the most discriminative skull features, we employed LASSO (Least Absolute Shrinkage and Selection Operator) regularization with 10-fold cross-validation, tuning across 100 penalty values. LASSO performs variable selection and regularization by shrinking less important coefficients to exactly zero, which is crucial when dealing with 20 potentially correlated cranial measurements. We selected the parsimonious penalty using the one-standard-error rule, favoring the simplest model within one standard error of the best performance to guard against overfitting. This process identified 14 key features: basilar.length, occipitonasal.length, palate.width, nasal.length, nasal.width, lacrymal.width, orbital.width, rostral.width, occipital.depth, foramina.length, mandible.width, mandible.depth, and ramus.height. These measurements capture overall skull size, facial structure, cranial depth, and mandibular characteristics, representing a comprehensive set of distinguishing features.

For our final classification model, we chose logistic regression using the LASSO-selected variables over more complex alternatives like random forests or KNN. This choice was made for multiple reasons. First, logistic regression provides interpretable coefficients showing exactly how each skull measurement contributes to species classification. This interpretability is lost with other methods like random forests and K-nearest neighbor, yet it is important for scientists who need to understand which anatomical features distinguish species and by how much. Second, logistic regression naturally handles binary outcomes through probability estimation and performs reliably with our sample size of 148 observations without requiring large amounts of training data. We addressed missing values through k-nearest neighbors imputation as seen in our variable recipe, which preserves relationships between similar observations. The model was validated using 10-fold cross-validation to ensure robust generalization. Our final model achieved strong predictive performance with 83.1% accuracy, 72.0% sensitivity (correctly identifying Fuliginosus group), and 91.0% specificity (correctly identifying Giganteus specimens). The high specificity indicates the model excels at correctly identifying giganteus specimens, which aligns with our observation that this species has distinct cranial morphology, especially in nasal dimensions.

# Implementation

We used tidymodels to implement this model building process. See code below for full details.

<details>
<summary>View Code</summary>
```{r}
#| message: false
#| warning: false

# group fuliginosus and melanops together (same species biologically)
kangaroo_data_lasso <- kangaroo %>%
  mutate(group_species = case_when(
    species == "giganteus" ~ "Giganteus", 
    species %in% c("fuliginosus", "melanops") ~ "Fuliginosus")) 

# encode species groups as numeric for lasso
lasso_kangaroo <- kangaroo_data_lasso %>%
  mutate(group_species = case_when(
    group_species == "Giganteus" ~ 0,
    group_species == "Fuliginosus" ~ 1)) %>%
  select(-species)  # remove the original species variable

# set up lasso model specification
lasso_spec <- linear_reg() %>% 
  set_mode("regression") %>% 
  set_engine("glmnet") %>% 
  set_args(mixture = 1, penalty = tune())

# create recipe with preprocessing steps 
kangaroo_recipe <- recipe(group_species ~ ., data = lasso_kangaroo) %>% 
  step_nzv(all_predictors()) %>% 
  step_impute_knn(all_predictors()) %>%
  step_dummy(all_nominal_predictors()) 

lasso_workflow <- workflow() %>% 
  add_recipe(kangaroo_recipe) %>% 
  add_model(lasso_spec)

set.seed(253)
lasso_models <- lasso_workflow %>% 
  tune_grid(
    grid = grid_regular(penalty(range = c(-5, 1)), levels = 100),
    resamples = vfold_cv(lasso_kangaroo, v = 10),
    metrics = metric_set(mae)
  )

# use best penalty to see variable selection
best_penalty <- lasso_models %>% 
  select_by_one_std_err(metric = "mae", desc(penalty))

final_lasso_model <- lasso_workflow %>% 
  finalize_workflow(parameters = best_penalty) %>% 
  fit(data = lasso_kangaroo)

# view selected variables with non-zero coefficients
final_lasso_model %>% 
  tidy() %>%
  filter(estimate!=0)

# create dataset with lasso-selected variables only
lasso_select <- kangaroo_data_lasso %>% 
  select(group_species, basilar.length, occipitonasal.length, 
         palate.width, nasal.length, nasal.width, lacrymal.width,
         orbital.width, .rostral.width, occipital.depth, foramina.length,
         mandible.width, mandible.depth, ramus.height)

# set up logistic regression specification
logistic_spec <- logistic_reg() %>%
  set_mode("classification") %>% 
  set_engine("glm")

# create recipe with knn imputation for selected variables
kangaroo_recipe <- recipe(group_species ~ ., data = lasso_select) %>% 
  step_impute_knn(all_predictors())

# combine recipe and logistic model into workflow
logistic_workflow <- workflow() %>% 
  add_recipe(kangaroo_recipe) %>%
  add_model(logistic_spec) 

# fit logistic regression model on full dataset
log_kangaroo <- logistic_workflow %>% 
  fit(data = lasso_select)

# evaluate model using 10-fold cross-validation
set.seed(253)
log_kangaroo_cv <- logistic_workflow %>%  
  fit_resamples(
    resamples = vfold_cv(lasso_select, v = 10),  
    control = control_resamples(save_pred = TRUE, event_level = 'second'),
    metrics = metric_set(accuracy, sens, spec)  
  )

# display cross-validated performance metrics
log_kangaroo_cv %>% 
  collect_metrics()




```
</details>

# Model Evaluation

```{r}
#| message: false
#| warning: false
#| echo: false

log_kangaroo_cv %>%
  collect_metrics() %>%
  knitr::kable(digits = 3,
               caption = "Logistic Regression Cross-Validation Metrics (10-fold CV)")


lasso_select_factor <- lasso_select %>%
  mutate(group_species = as.factor(group_species))

log_predictions <- log_kangaroo %>%
  augment(new_data = lasso_select_factor)

log_cm <- log_predictions %>%
  conf_mat(truth = group_species, estimate = .pred_class)

log_cm

log_predictions %>%
  conf_mat(truth = group_species, estimate = .pred_class) %>%
  autoplot(type = "heatmap") +
  labs(title = "Logistic Regression Confusion Matrix",
       subtitle = "Binary Classification (Giganteus vs Fuliginosus)") +
  theme_minimal()

log_kangaroo_cv %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "accuracy") %>%
  ggplot(aes(x = id, y = .estimate)) +
  geom_point(size = 3, color = "darkgreen") +
  geom_hline(
    yintercept = mean(
      log_kangaroo_cv %>%
        collect_metrics(summarize = FALSE) %>%
        filter(.metric == "accuracy") %>%
        pull(.estimate)
    ),
    linetype = "dashed", color = "red"
  ) +
  labs(
    title = "Logistic Regression Accuracy Across 10-Fold Cross-Validation",
    subtitle = "Binary Classification",
    x = "Fold",
    y = "Accuracy"
  ) +
  theme_minimal() +
  coord_flip() +
  ylim(0.6, 1.0)


```

# Contributions

# Appendix

```{r}
#| eval: false
# put code for any other models or visualizations that you considered here
# use comments to explain what your code is doing
```


# Random Tree and Forest

```{r }
#| eval: false
tree_spec <- decision_tree() %>%
  set_mode("classification") %>%
  set_engine("rpart") %>%
  set_args(cost_complexity = tune(), min_n = 2, tree_depth = 30)

tree_recipe <- recipe(species ~ ., data = kangaroo)

tree_wf <- workflow() %>%
  add_recipe(tree_recipe) %>%
  add_model(tree_spec)


set.seed(253)
tree_models <- tree_wf %>%
  tune_grid(
    grid = grid_regular(cost_complexity(range = c(-5, 0.1)), levels = 20),
    resamples = rs,
    metrics = metric_set(accuracy))

best_cost <- select_best(tree_models, metric = "accuracy")
final_tree <- tree_wf %>% finalize_workflow(best_cost) %>% fit(kangaroo)

final_tree %>% extract_fit_engine() %>% rpart.plot()
```

```{r}
#| eval: false
tree_models %>%
  collect_metrics() %>%
  dplyr::filter(.metric == "accuracy") %>%
  dplyr::arrange(desc(mean)) %>% 
  dplyr::slice(1)
```

```{r}
#| eval: false  
rf_spec <- rand_forest() %>%
  set_mode("classification") %>%
  set_engine("ranger") %>%
  set_args(
    mtry = NULL,
    trees = 500,
    min_n = 2,
    probability = FALSE,
    importance = "impurity")

age_forest <- rf_spec %>% fit(species ~ ., data = kangaroo)

imp_vec <- age_forest %>% extract_fit_engine() %>%
  pluck("variable.importance") %>% sort(decreasing = TRUE)
imp_vec

age_forest %>% vip(geom = "point", num_features = 15)
```

```{r}
#| eval: false
#KNN
knn_select <- kangaroo %>% 
  select(species, basilar.length, occipitonasal.length, 
         palate.length, palate.width, nasal.length, 
         nasal.width, squamosal.depth)

knn_spec <- nearest_neighbor() %>%
  set_mode("classification") %>%
  set_engine(engine = "kknn") %>%
  set_args(neighbors = tune())

variable_recipe <- recipe(species ~., data = knn_select) %>%
  step_nzv(all_predictors()) %>%
  step_impute_knn(all_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors())

knn_workflow <- workflow() %>%
  add_recipe(variable_recipe) %>%
  add_model(knn_spec)

set.seed(253)
knn_models <- knn_workflow %>%
  tune_grid(
    grid = grid_regular(neighbors(range = c(1, 74)), levels = 50),
    resamples = vfold_cv(knn_select, v = 10),
    metrics = metric_set(accuracy)
  )

knn_models %>%
  autoplot()

best_k <- knn_models %>%
  select_best()
best_k

knn_models %>%
  collect_metrics() %>%
  filter(neighbors == best_k$neighbors)

final_knn_model <- knn_workflow %>%
  finalize_workflow(parameters = best_k) %>%
  fit(data = knn_select)
```

```{r}
#| eval: false
tree_select <- kangaroo %>% 
  select(species, basilar.length, occipitonasal.length, 
         palate.length, palate.width, nasal.length, 
         nasal.width, squamosal.depth)

# Decision Tree
tree_spec <- decision_tree() %>%
  set_mode("classification") %>%
  set_engine("rpart") %>%
  set_args(cost_complexity = tune(), min_n = 2, tree_depth = 30)

tree_recipe <- recipe(species ~ ., data = tree_select) %>%
  step_impute_knn(all_predictors())  

tree_wf <- workflow() %>%
  add_recipe(tree_recipe) %>%
  add_model(tree_spec)

set.seed(253)
tree_models <- tree_wf %>%
  tune_grid(
    grid = grid_regular(cost_complexity(range = c(-5, 0.1)), levels = 20),
    resamples = vfold_cv(tree_select, v = 10),  # 10-fold CV
    metrics = metric_set(accuracy)
  )

best_cost <- select_best(tree_models, metric = "accuracy")
final_tree <- tree_wf %>% 
  finalize_workflow(best_cost) %>% 
  fit(tree_select)

final_tree %>% extract_fit_engine() %>% rpart.plot()

tree_models %>%
  collect_metrics() %>%
  dplyr::filter(.metric == "accuracy") %>%
  dplyr::arrange(desc(mean)) %>% 
  dplyr::slice(1)
```

#random forest

```{r}
#| eval: false
conflicted::conflicts_prefer(ranger::importance)  

rf_spec <- rand_forest() %>%
  set_mode("classification") %>%
  set_engine("ranger") %>%
  set_args(
    mtry = NULL,
    trees = 500,
    min_n = 2,
    probability = FALSE,
    importance = "impurity"
  )

rf_recipe <- recipe(species ~ ., data = tree_select) %>%
  step_impute_knn(all_predictors())  

rf_wf <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_spec)

species_forest <- rf_wf %>% 
  fit(tree_select)

imp_vec <- species_forest %>% 
  extract_fit_engine() %>%
  pluck("variable.importance") %>% 
  sort(decreasing = TRUE)

imp_vec

library(vip)
species_forest %>% vip(geom = "point", num_features = 7)  # 7 features total


set.seed(253)
rf_cv <- rf_wf %>%
  fit_resamples(
    resamples = vfold_cv(tree_select, v = 10),
    metrics = metric_set(accuracy)
  )

# View accuracy
rf_cv %>% collect_metrics()
```

```{r}
#| eval: false
## KNN Model (3 Species Classification)

### Cross-Validation Metrics
set.seed(253)
knn_cv <- knn_workflow %>%
  finalize_workflow(best_k) %>%  # Finalize with best k first
  fit_resamples(
    resamples = vfold_cv(knn_select, v = 10),
    control = control_resamples(save_pred = TRUE),
    metrics = metric_set(accuracy)
  )

knn_cv_metrics <- knn_cv %>% collect_metrics()
knn_cv_metrics %>%
  knitr::kable(digits = 3, caption = "KNN Cross-Validation Metrics (10-fold CV)")

### Confusion Matrix
# Convert species to factor
knn_select_factor <- knn_select %>%
  mutate(species = as.factor(species))

knn_predictions <- final_knn_model %>%
  augment(new_data = knn_select_factor)

knn_cm <- knn_predictions %>%
  conf_mat(truth = species, estimate = .pred_class)

knn_cm

# Visualize confusion matrix
knn_predictions %>%
  conf_mat(truth = species, estimate = .pred_class) %>%
  autoplot(type = "heatmap") +
  labs(title = "KNN Confusion Matrix",
       subtitle = "All 3 Species Classification (k=5)") +
  theme_minimal()

### Visualize Accuracy Across CV Folds
knn_cv %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "accuracy") %>%
  ggplot(aes(x = id, y = .estimate)) +
  geom_point(size = 3, color = "steelblue") +
  geom_hline(yintercept = mean(knn_cv %>%
                                  collect_metrics(summarize = FALSE) %>%
                                  filter(.metric == "accuracy") %>%
                                  pull(.estimate)),
             linetype = "dashed", color = "red") +
  labs(title = "KNN Accuracy Across 10-Fold Cross-Validation",
       subtitle = "3 Species Classification (k=5)",
       x = "Fold",
       y = "Accuracy") +
  theme_minimal() +
  coord_flip() +
  ylim(0.5, 0.85)

```
